# AI Payphone Configuration
# Copy this to .env and customize
# Model recommendations updated January 2026

# Debug mode
DEBUG=false
LOG_LEVEL=INFO

# AudioSocket Server
AUDIO_AUDIOSOCKET_HOST=0.0.0.0
AUDIO_AUDIOSOCKET_PORT=9092

# Speech-to-Text (faster-whisper fallback when Hailo unavailable)
# Speed: tiny (~0.7-1.2s latency), Quality: large-v3-turbo, Balanced: base
# Future: Moonshine offers 5x speed improvement over Whisper Tiny
STT_MODEL_NAME=tiny
STT_DEVICE=hailo
STT_COMPUTE_TYPE=int8
STT_LANGUAGE=en

# Language Model (Ollama on Pi #2)
# For dual-Pi setup: LLM_HOST=http://10.10.10.11:11434
# Recommended models:
#   - Speed: llama3.2:3b-instruct-q4_K_M (~5-6 TPS)
#   - Quality: ministral:8b (~2-3 TPS, best conversational)
#   - Balanced: qwen2.5:7b-instruct-q4_K_M (~2 TPS)
LLM_HOST=http://10.10.10.11:11434
LLM_MODEL=llama3.2:3b-instruct-q4_K_M
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=150
LLM_TIMEOUT=10.0

# Text-to-Speech (Kokoro-82M)
# Mode: "local" (default) or "remote" (offload to Pi #2)
# Kokoro remains gold standard for edge TTS (Jan 2026)
TTS_MODE=local
# Remote TTS server (when mode=remote)
# Run tts_server.py on Pi #2: python tts_server.py
TTS_REMOTE_HOST=http://10.10.10.11:10200
TTS_REMOTE_TIMEOUT=10.0
# Kokoro model settings (for local mode or remote server)
# Use quantized models for better performance:
#   - kokoro-v1.0.onnx (default, FP32)
#   - kokoro-v1.0-int8.onnx (2x faster)
TTS_MODEL_PATH=kokoro-v1.0.onnx
TTS_VOICES_PATH=voices-v1.0.bin
TTS_VOICE=af_bella
TTS_SPEED=1.0

# Voice Activity Detection (Silero VAD v5)
# Optimized for telephony audio (8kHz)
# Alternative: TEN VAD via sherpa-onnx for lower latency
VAD_THRESHOLD=0.5
VAD_MIN_SPEECH_DURATION_MS=250
VAD_MIN_SILENCE_DURATION_MS=800
VAD_SPEECH_PAD_MS=300

# Timeouts
TIMEOUT_SILENCE_PROMPT=10
TIMEOUT_SILENCE_GOODBYE=30
TIMEOUT_MAX_CALL_DURATION=1800
